project_name: "lunar_lander"

runtime:
  use_cuda: true
# Environment Configuration
environment:
  type: "LunarLander"
  seed: 502
  render_mode: "rgb_array"

# Monte Carlo Tree Search (MCTS) configuration
training_data_generator:
  num_episodes: 1                   # total number of episodes for self-play/learning
  max_steps_per_episode: 10
  total_time: 3600
  epsilon: 1.0
  epsilon_decay: 0.995
  mcts:
      selection_strategy: "puct"          # can be "uct" or "puct"
      max_iterations: 50                       # maximum iterations (set to 0 if using time-based termination)
      max_time: 100.0                      # maximum search time per move (in seconds)
      model_look_ahead: 1
      discount_factor: 0.998


# Training hyperparameters
training:
  learning_rate: 0.001
  epochs: 100
  batch_size: 32
  replay_buffer_size: 40
  alpha: 0.6
  betas: [0.9, 0.999]
  look_back: 4                        # number of past states to include in the input sequence
  roll_ahead: 5
  mini_batch_size: 256

validation:
  video_upload_interval: 10
  simulation_count: 3
  simulation_depth: 300

# Neural network configurations
networks:
  latent_shape: [6, 6, 3]
  representation:
    downsample:
      # - type: "conv_layer" # in 96x96x3 out 48x48x3
      #   out_channels: 3
      #   kernel_size: 2
      #   stride: 2
      #   padding: 0
      #   activation: "relu"
      - type: "res_block" # in 48x48x3 out 48x48x3
        in_channels: 3
        out_channels: 3
        kernel_size: 3
        stride: 1
        padding: 1
        activation: "relu"
        pool_stride: 1
        pool_kernel_size: 1
      # - type: "pool_layer" # in 48x48x3 out 24x24x3
      #   kernel_size: 2
      #   stride: 2
      #   padding: 0
      #   pool_type: "max"
      # - type: "conv_layer" # in 24x24x3 out 12x12x3
      #   out_channels: 3
      #   kernel_size: 2
      #   stride: 2
      #   padding: 0
      #   activation: "relu"
      # - type: "pool_layer" # in 12x12x3 out 6x6x3
      #   kernel_size: 2
      #   stride: 2
      #   padding: 0
      #   pool_type: "max"
    res_net:
      - in_channels: 3
        out_channels: 3
        kernel_size: 3
        stride: 1
        padding: 1
        activation: "relu"
        pool_stride: 1
        pool_kernel_size: 1
  dynamics:
    res_net:
      - in_channels: 3
        out_channels: 3
        kernel_size: 3
        stride: 1
        padding: 1
        activation: "relu"
        pool_stride: 1
        pool_kernel_size: 1
    reward_net:
      - out_features: 128
        activation: "relu"
      - out_features: 1
        activation: "relu"
  prediction:
    res_net:
      - in_channels: 3
        out_channels: 3
        kernel_size: 3
        stride: 1
        padding: 1
        activation: "relu"
        pool_stride: 1
        pool_kernel_size: 1

    value_net:
      - out_features: 1
        activation: "relu"
    policy_net:
      - out_features: 5
        activation: "relu"
